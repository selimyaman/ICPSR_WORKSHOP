# Materials for the workshop "Navigating the Landscape of Transformers: A Hands-On Introductory Workshop"

Welcome to the GitHub repository dedicated to "Navigating the Landscape of Transformers: A Hands-On Introductory Workshop", a workshop tailored to offer insights and hands-on experience with NLP tools. This workshop is a part of the course `Machine Learning: Applications in Social Science Research` at [ICPSR 2023](https://www.icpsr.umich.edu/web/pages/sumprog/). Materials are prepared by [Selim Yaman](https://www.selimyaman.com).


This repository houses a selection of Jupyter notebooks that serve as core resources for the workshop. If you wish to actively run the notebooks, simply open the .ipynb files right here on GitHub and select the Open in Colab button situated at the top of the notebook. This will subsequently launch the notebook in Google Colab, where you'll have the ability to execute the code using free cloud-based CPUs or GPUs.


**Workshop Overview** 

Transformers, particularly models like BERT, are gaining traction within the field of social sciences. However, there seems to be an enduring misunderstanding that these models are highly complex and hard to utilize. This workshop aims to dispel such notions by demonstrating how accessible and user-friendly these models have become, thanks to powerful open-source packages like Hugging Face Transformers.

We will kick off the workshop with an easily graspable introduction to the concept of transfer learning, while highlighting its significance and limitations within social science applications. The heart of the workshop is an interactive session, where we'll collectively train and evaluate a Transformer for a standard political science task. The course will predominantly employ Python for demonstration, however, it's not a prerequisite for attendees to be familiar with it. I warmly encourage the participation of individuals regardless of their prior experience with Python or Transformers.

Upon concluding the workshop, you will be equipped with a set of Jupyter notebooks that will empower you to train your own Transformer using your custom data for upcoming research initiatives. This interactive, practical approach is designed to provide a strong foundation and to stimulate the integration of Transformer models into your future projects.





